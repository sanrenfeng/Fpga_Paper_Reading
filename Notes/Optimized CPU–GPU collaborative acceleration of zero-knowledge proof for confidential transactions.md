### Optimized CPU–GPU collaborative acceleration of zero-knowledge proof for confidential transactions

​						优化的CPU-GPU协同加速零知识证明

 #### 摘要

​	区块链的潜在应用范围远比其数字货币的起源更广泛，可能包括管理智能合约、受版权保护的作品以及商业或组织登记处的数字化。不足为奇的是，交易信息的机密性在这些各种区块链应用中是需要的，但不幸的是，目前还没有得到很好的支持。零知识证明(如 bulletproofs )由于能够在不直接泄露信息的情况下验证信息的真实性，是区块链中提供交易机密性的良好候选方案。然而，零知识证明仍然存在计算开销大和吞吐量低的问题，并且 Bulletproofs 在区块链应用中仍然存在计算效率低下的问题。边缘计算通过提供强大的 GPU 来满足机密事务对高性能的强烈需求，可以作为一种有益的选择。在本文中，我们首先提出了一个CPU - GPU 协同框架来加速 Bulletproofs 的内积参数。实验表明，我们的实现获得了平均 3.7 倍的加速比。在此基础上，本文还提出在支持 GPU 的边缘设备、提供机密和透明事务处理的事务处理系统上构建一个高效的 Bulletproofs。与原始Bulletproofs 相比，GPU 加速实现可以获得高达4.7倍的加速比。当需要多个Bulletproofs 捆绑执行时，工作重点放在了内存优化和数据分割上，进一步将速度提高了 30 %。最后，当机密和透明事务都在边缘并行时，整个事务处理系统获得了1.5倍的加速比。

#### 介绍部分


​	区块链技术因其数据不可篡改的独特特性，引起了工业界和学术界的高度关注。它使一个用户社区可以在没有权限的情况下以分散的方式在共享分类账中记录交易，而这些交易在创建后不能轻易更改。然而，在区块链中，交易是全局发布的，并且在大多数区块链应用中没有加密，这些应用也被称为透明交易，人们对缺乏隐私性的担忧也越来越高。数据提供商往往希望敏感数据的私密性，但是公有链上的交易是公开透明的。如果我们希望将区块链应用于涉及隐私敏感信息的交易中，这些事实造成了实践中的困难。不充分的金融隐私会对商业和个人交易产生严重的安全和隐私影响。

​		机密交易( CT ) 是一种加密方法，通过保持交易信息的私密性同时保留公共网络验证分类账条目的能力来增加区块链的隐私性和安全性。它对交易中需要验证的每一条信息进行零知识证明，以确保信息合法且可验证的同时不泄露信息的内容。例如，假设交易的双方是 A 和 B ，并且 A 在开始时有两个账户，而 B 有一个账户没有余额。如果 A 现在要将 10 - BTC 转移给 B，则无机密机制的交易如图顶部所示。可见，A 将资金从账户 1、2 转移到 B 后，清算了原账户 1、2 的余额，然后在交易结束后又有一个新的账户3来存储余额。由于没有应用保密机制，所有的平衡细节都是公开的。

![image-20230915195233861](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915195233861.png)

​			从直观上看，零知识证明技术可以在不泄露账户余额任何信息的情况下确保有效交易的发生。图底部显示了零知识证明技术应用后的交易流程，其中验证了这一点 ： 

​	证明1：账户3的余额不小于0；

​	证明2：账户余额4不小于0；

​	证明3：账户1和账户2的余额之和不小于账户3和账户4的余额之和。

​			有了上述三个证明，就可以在不泄露剩余余额明细的情况下实施 BTC 转让交易。

​			零知识算法最初是在密码学领域提出的，由于其在区块链领域的重要性，近年来得到了广泛的研究。2013年，Sasson等人提出了 zk - SNARK 算法，该算法被加密货币 Zash 用来解决比特币型区块链的感知匿名性问题。Zk - SNARK证明所需计算量小、速度快，**但依赖于最初的"信任系统"设置，而这一设置被批评为固有的安全缺陷。可信设置是指在进行协议证明和认证之前，需要设置和生成一些公共参数。**2014年，Sasson 等人提出了 zk - STARK 算法，该算法不再需要可信的第三方，但同时计算量和证明文件的大小都显著增加。Bulletproofs 在2018年被提出，同样不需要可信第三方。同时，它将许多复杂的计算转化为内积运算，有效地减少了计算量和证明文件的大小。更重要的是，由 Bulletproofs 产生的证明大小是对数变换的，这意味着证明的大小只会随着交易的急剧增加而稍微变大。这有利于其在大数据场景中的应用。总之，与 zk - STARK 相比，Bulletproofs 不需要可信设置，计算量更小，应用范围更广。

​			然而，虽然 Bulletproofs 证明是最有效的零知识证明，但计算代价仍然很高。由于保密交易在应用中通常涉及巨大的证明量，较高的计算开销使得保密交易很难在实际中得到广泛的应用。因此，需要对机密事务进行并行优化，以提高执行速度。

​			幸运的是，在这种情况下，边缘计算可以成为一个有用的选择。边缘计算通常配备强大的 GPUs 和有能力的处理器，由于其低延迟的形式和相当高的带宽来满足基础设施应用的需求。它满足了机密交易对高性能基础设施的强烈需求，以及对增长、安全和分散的独特需求，并提供了一种无缝的方式来部署和维护地理上多样化的存在。为了使用户能够更加可靠地访问系统，可以利用机密事务在边缘计算系统的参与者之间形成互连，从而实现信用传递、数据同步和资源共享。此外，区块链的数据一致性和防篡改特性也可以保证系统中数字信息的完整性。因此，随着这两种技术的进步，零知识证明和边缘计算的改进集成将是机密交易系统的一个有前途的解决方案。

​			我们首先提出通过充分解锁 CPU - GPU 系统的能力来并行化内积计算来加速 Bulletproofs 算法。然后，考虑到 GPU 的架构限制，我们提出优化一个同时支持机密交易和透明交易的安全系统，通过充分释放边缘计算的能力来并行化包括 Bulletproofs  和数字签名在内的批量密码操作。我们首先基于边缘计算的交易过程为典型应用提供常见的零知识证明。然后，我们实现了一个集成的优化机制，包括零拷贝内存管理、数据查找、数据分割和流水，可以进一步提高性能。最后，在支持GPU的边缘环境中对安全系统进行测试，并对不同的个体优化技术组合进行评估。整个事务处理系统在提供信息安全的同时，获得了接近1.5倍的加速比。

​			我们的贡献总结如下：

1. 通过CPU - GPU系统中内积计算的完全并行化加速验证 Bulletchecks 算			法，并将执行时间缩减 3 - 4 倍；
1. 优化零知识证明的加速模型，通过内存优化和数据分割方法，将零知识证明的运算速度提高30 %；
1. 提出同时支持机密和透明事务的安全模型，实现了一堆并行的零知识证明加速；
1. 在保证数据机密性的同时减少计算时间。优化后的零知识证明算法的速度比原 Bulletproofs 算法实现快4.6倍，整体模型的速度提高了近1.5倍。
	

​	论文的其余部分组织如下。第 2 节讨论了零知识证明算法的潜在应用前景，并进一步阐述了零知识证明算法的相关工作。第 3 节给出 Bulletproofs 内积论证和椭圆曲线点算法的基本概念和一般信息。第4节描述了所设计的CPU - GPU协同算法，并给出了一个基于零知识证明的事务处理系统，该系统同时支持机密和透明事务。然后，我们在第5节中描述了基于三种方法的优化机制。第6节讨论了系统的具体实现和各项优化技术。第七节对系统和技术进行了评估，第八节给出了结论。

#### 相关工作

​		主要的隐私保护方案可以分为五类，包括混合硬币、多方安全计算、环签名、可信计算和零知识证明。混合硬币通过简单的混淆操作完成用户隐私保护。环签名是一种数字签名方案，其主要原理是将发起该行为的用户隐藏在一个群组中进行隐私保护。这两种方法实际上都是部分隐私保护，无法阻止群体中混入的恶意行为体的攻击。多方安全计算的过程相对复杂，导致其性能较差，实现困难，难以支持大规模应用。基于可信计算的解决方案可以通过硬件兼顾正确性、隐私性和高性能，但硬件的设计和制造成本较高，因此难以部署。零知识证明算法是指证明者可以在不向验证者提供任何有用信息的情况下，使验证者相信某个语句是正确的。与其他算法相比，它提供了完整的隐私保护，并且实现相对简单，适合大规模应用。

​		**由于零知识证明算法可以在不泄露信息的情况下证明信息是有效的，因此它有潜力在许多隐私关键的应用中得到广泛的应用，以实现安全和可验证的数据处理。零知识证明的特性可以导致一些有趣的应用，包括电子投票，在线拍卖，匿名凭证等。在分布式账本技术和区块链技术的背景下，也有许多有趣的应用，例如 Pedersen 承诺，条款，以及区块链上的各种智能合约。同时，零知识证明还可以与其他先进技术结合，包括可验证数据库外包和可验证机器学习。零知识证明也可以应用在大型科学装置中。上海同步辐射装置( Shanghai Synchrotron Radiation Facility，SSRF )是我国拥有最多用户数和科研成果的科学装置。由于SSRF 的原始数据可能在版权市场上进行交易，因此基于 bulletproofs 的机密交易系统被认为是数据版权交易的候选解决方案。**

​		虽然 Bulletproofs 不需要可信设置且比 ZK - STARK 算法更快，但在实际应用中仍然存在计算量大、吞吐量高的问题。因此，可以利用异构加速框架对内积运算和模乘运算进行并行加速，提高算法的运算速度。

​		**异构加速一般采用具有协处理器结构的 CPU。根据零知识证明异构加速中协处理器的不同，现有的研究可以分为：CPU 加专用加速器、CPU 加 FPGA 、CPU加 GPU。专用加速器是指针对固定场景设计的特定芯片，如 ChainMaker 发布的96 核区块链专用加速器芯片，可以将数字签名的速度提高 2 0倍。但该方法的缺点是实现难度大、成本高、通用性差。在区块链的加速中，用 FPGA 加速是一种比较常见的研究方案，实现方法也比较类似，如加速 FFT 运算、Montgomery乘法和签名算法。GPU 也是异构加速中常用的设备。例如，Zhang 等人设计了一个带有两个子系统的定制流水线加速器来处理这两个密集型计算任务。与 FPGA 相比，其优势在于 GPU 环境往往已经存在于零知识证明场景中。因此，不需要额外的环境配置，CPU - GPU异构方式实现相对简单。**

​		**常见的 GPU 并行优化策略包括内存优化、传输过程优化、结构优化等。内存优化最重要的是合理利用各级内存，特别是缓存、共享内存和常量内存。传输的优化实际上是减少内存与视频存储器之间的数据交换，同时还需要依靠内存调度。Ren 等人提出了 Sentinel 架构，该架构主要利用内存分配来获得张量的大小和周期，并尽可能地将热点张量放在共享内存中。结构优化是指对算法结构进行适当的修改，使其更适合在 GPU 中加速，如循环展开或图形展开。**例如，Morishima 等人提出了适用于GPU处理的子图结构，使得所有的子图制作、特征提取和异常检测都在GPU中进行。综上所述，GPU的并行优化需要根据算法和场景的特点选择合适的解决方案。



#### 背景

​		目前零知识证明领域的加速方案都是对 zk - snark 算法和 zk - stark 算法进行加速，且大多是基于 FPGA 实现加速或者通过改变硬件结构，如添加流水线加速器实现硬件加速。在GPU加速方面，区块链项目文件币使用 GPU 加速来缩短zk - snark 中的 PoST 证明时间，Long等提出了一种CPU - GPU系统来加速矩阵分解中 IPR 求解的计算任务。密码学的隐私保护是当前的一个研究热点。Qiu等人提出了一种新颖的基于二分匹配的隐私保护方法，并吸引了大量的后续工作。Dai等人对智能手机中的隐私保护进行了一些重要的研究。

​		Bulletproofs 提供了一种新的零知识论证，仅依靠离散对数假设即可证明秘密承诺值位于给定区间内。一个论据是一个证明，只有当证明者是计算有界的，并且某些计算困难假设成立时，该论据才成立。内积论证证明了承诺向量之间存在内积关系。Bulletproofs  是建立在Bootle等提出的沟通有效的内积论基础上的。该论证证明了证明者知道满足给定内积关系的两个绑定彼泽森向量承诺的开头。

##### 内积论证

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915215657099.png" alt="image-20230915215657099" style="zoom: 67%;" />


​		图 2 描述了 Bulletproofs   中内积论证的整体互动过程。Bulletproofs   中有一个证明者和一个验证者。如图2所示，验证者向证明者重复发送一个随机挑战𝑥，证明者根据收到的 𝑥 计算两个变量 𝐿，𝑅，并将 𝐿，𝑅 反馈给验证者。

​		我们首先介绍了证明者和验证者交互过程中使用的符号。令𝐠，𝐡∈ $G^n$表示两个独立的生成器，𝑢，𝑃∈G 表示绑定向量承诺。变量 𝑐 ∈ $Z_p$ 为标量。在内积论证中，证明者证明了存在两个向量 𝐚，𝐛∈ $Z_p^n$ 满足𝑃 = $g^ah^b$和𝑐 =⟨𝐚，𝐛⟩，使得

​			(𝐠，𝐡∈ $G^n$ , 𝑃∈G, 𝑐 ∈ $Z_p$; 𝐚，𝐛∈ $Z_p^n$   ) :

​			𝑃 = $g^ah^b$ ^ 𝑐 =⟨𝐚，𝐛⟩                              (1) 

​		我们进一步将 𝑃 限定为Pedersen 向量承诺 ( 𝐚、𝐛、**𝑐**)。对式( 1 ) 作如下修改。

​			(𝐠，𝐡∈ $G^n$ , 𝑃∈G, 𝑐 ∈ $Z_p$; 𝐚，𝐛∈ $Z_p^n$   ) :

​			P = $g^ah^bu^{<a,b>}$


​		最初，当 𝑛  >  1时，证明器的输入参数为( 𝐠、𝐡、𝑢、𝑃、𝐚、𝐛)，并且令 𝑛′= 𝑛/2，则 𝑃 可改写为 𝑃 = 𝐻 ( $𝐚_{[∶𝑛′]}$ , $𝐚_{[ 𝑛′∶]}$ , $𝐛_{[∶𝑛′]}$ , $𝐛_{[ 𝑛′∶]}$ , 𝑐)。为了保证验证者能够计算出新的 Pedersen 承诺，证明者需要向验证者提供 𝐿 和 𝑅，定义如下 :  

![image-20230915220959715](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915220959715.png)						

​		随后，验证者生成随机挑战 𝑥 ← $Z_𝑝^*$ 并发送给证明者，证明者需要进行计算

![image-20230915220948406](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915220948406.png)


​		并更新输入( 𝐠′, 𝐡′, 𝑃′, 𝐚′, 𝐛′)。同时，在收到 ( 𝐿、𝑅) 后，验证者计算 𝐠′、𝐡′、𝑃′ 并更新输入。重复上述交互过程，直到 𝑛′ = 1。最后，验证者将 𝑃′ 与 𝐻𝐚′, 𝑥 𝐚′, 𝑥 𝐛′,  $𝑥 ^{-1}$ 𝐛′,⟨𝐚′, 𝐛′⟩)进行比较。如果两个值相等，则认为验证成功。

​		内积论证的计算步骤较多，如公式所示。( 3 ) - ( 4 )可以并行执行。此外，由于 Bulletproofs  通常需要大量的内积参数，如果有效地加速内积参数，Bulletproofs  的性能将得到很大的提升。

#####  椭圆曲线点算法

​		在 Bulletproofs 中，内积论证的实现使用了安全的椭圆曲线密码( ECC )，它是基于有限(素数)域上椭圆曲线的代数结构。因此，用椭圆曲线上的点代替数作为基本的数学对象，如加法和乘法。

​		椭圆曲线是由$𝑦^2 = 𝑥^3 + 𝑎𝑥 + 𝑏$ 定义的一组点 并且 𝑎， b满足$4𝑎^3 + 27𝑏^2≠0 $，保证了曲线不含奇异点。注意椭圆曲线关于 𝑥 轴对称。椭圆曲线点加法如图 3 和 4 所示。 

​		设直线与椭圆曲线相交于点( 𝑃、𝑄、𝑅)，定义𝑃 + 𝑄 + 𝑅 = 0 ( 0 表示单位元,为无穷远处的点)。三个点( 𝑃、𝑄、𝑅)构成一个椭圆曲线群。当给定 𝑃 和 𝑄 两个点时，椭圆曲线点加法可视为求解 𝑅，即 𝑃 + 𝑄 = - 𝑅 .

​		令{ ( $x_i、y_i$)，𝑖∈𝑃，𝑄，𝑅 }分别表示𝑃，𝑄，𝑅的坐标。假设一个实数域，当𝑃 ≠ 𝑄时，直线 𝜆 的斜率如下

​								𝜆 = $𝑦_𝑄 − 𝑦_𝑃 / 𝑥_𝑄 − 𝑥_𝑃  $ , 𝑃 ≠ 𝑄.

​		当 𝑃 = 𝑄 时，斜率 𝜆 计算为(切线问题、求导)

​								𝜆 = $(3𝑥^2_𝑃 + 𝑎 )/ 2𝑦_𝑃$ , 𝑃 = 𝑄

​		那么 𝑅 的坐标可以计算为:

​				$𝑥_𝑅 = 𝜆^2 − 𝑥_𝑃 − 𝑥_𝑄, 𝑦_𝑅 = 𝜆(𝑥_𝑃 − 𝑥_𝑅) − 𝑦_𝑃 .$


​		然而，在加密中椭圆曲线被定义在有限域 $ F_p$ 中而不是实数域中。有限域运算遵循模数法则，因此线段的斜率和 𝑅 的坐标计算如下，其中 𝑝 为素数。

![image-20230915223249689](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915223249689.png)


​	最后，给定𝑅的坐标，通过寻找𝑅的对称点，即( $ 𝑥_𝑅 , - 𝑦_𝑅$)，可以得到椭圆曲线加点运算 𝑃 + 𝑄 = - 𝑅 。椭圆曲线的点乘运算可以通过重复应用加法运算实现，即𝑛0 𝑃 = 𝑃 + 𝑃 + E + 𝑃。在 Bulletproofs 的内积证明和验证中，有大量的椭圆曲线点加法和乘法运算可以并行化。这将有效地提高 Bulletproofs 中内积参数的运算速度。

![image-20230915223408831](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915223408831.png)

##### 系统描述

​	首先是基于 Bulletproofs 的加速算法设计。在 Bulletproofs 中，最重要的部分是电路证明和范围验证，它们都是基于内积论证实现的。电路证明和范围验证的过程包含了大量的向量内积运算和基于有限域椭圆曲线的模运算，可以通过并行计算进行加速。整个CPU - GPU协同加速框架如图5所示。

![image-20230915223613029](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915223613029.png)

​		在图 5 中，有两个计算组件，即 CPU 主机和 GPU 设备。在主机端初始化Bulletproofs 电路和范围验证模块，包括打样和验证阶段的数据输入、内存分配和参数设置。当 Bulletproofs 算法进入内积和椭圆模运算的并行计算部分时，主机基于 CUDA 平台将需要计算的数据和核拷贝并传输到 GPU 设备中并行执行。计算完成后，结果不会立即传回主机，而是暂时存储在 GPU 的全局内存中，直到结果需要主机使用为止。

​		在图 6 中，我们提出了一个通用的基于零知识证明的安全系统架构，用于科学数据共享和追踪等典型应用。在实际应用中，通常存在两种交易，即机密交易和透明交易。在机密交易中，数据在整个过程中都是保密的；同时，在透明的交易过程中，数据是公开的。如图6所示，系统被拆分为两个部分。第一种支持机密交易，第二种支持透明交易。在实际应用中，大量事务流进入系统并并发执行。因此，在系统中并行实现了多个零知识证明而不是单个证明。为了进一步提高系统的性能，需要探索系统的高并行性。

![image-20230915223906512](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915223906512.png)

#### 机密交易

​		在保密交易中，零知识证明被用来证明在不泄露具体交易内容的情况下，交易可以合法缔结。此外，在机密交易的不同功能单元上并行应用多个零知识证明，如数据验证、地址验证等。为了便于执行多重证明的并行性，提高执行效率，将机密事务分为 4 个阶段进行流水线处理。这 4 个阶段分别是：事务构造、零知识证明计算、签名和事务发送。

- 事务构造：事务构造是定义事务数据结构、赋值、初始化事务的输入输出队列、根据事务地址创建对象并添加到地址队列的过程。
- 零知识证明计算：当事务构造完成后，通过零知识证明来验证交易过程。对于每一笔交易，需要对信息的不同组成部分进行多次零知识证明。例如，这些信息包括 ( 1 )地址的所有权，( 2 )交易的计算过程是否正确，( 3 )交易本身是否存在冲突，这些信息都是通过零知识证明独立验证的。在所有组件被验证为合法后，对事务进行签名并发送到目的地。
- 签名：签名是将额外的数据附加到数据单元或在数据单元上进行的加密转换的过程。附带的附加数据是数据真实性的有效证明。除了保证数据的不可篡改性，数据的隐私性也得到了保护。因此，需要两对签名密钥。第一对密钥用于保证不可变性。更具体地说，私钥对数据进行加密以保证数据不可篡改，然后签名的数据需要通过公钥进行验证。第二对对称密钥用于加密私有数据；
- 事务发送：将经过验证和签名的交易发送到目的地。

##### 透明交易


​	透明交易是保密交易的外围补充，有助于完成公共数据的交易。在透明交易中，所有信息都是公开可追溯的，这比保密交易更加简洁。因此，许多加密过程可以省略。透明的交易过程是流水线式的，**包括交易构建、签名和交易发送3个阶段。与保密交易相比，透明交易不需要零知识证明**。事务构造所需的数据结构也比较简单。在图 6 中，透明值池( TVP )用于存储透明事务中的公共数据和地址。

##### 数据抓取的优化机制


​	一般来说，GPU 的结构与 CPU 的结构十分相似。它们都利用了缓存层、全局内存和内存控制器的内存结构。一个高水平的 GPU 架构是关于数据并行的吞吐量计算和将可用的核心投入工作，而不是像 CPU 那样专注于低延迟的高速缓存访问。图 7 给出了一个典型的 GPU 存储结构。GPU 设备具有几种不同的内存空间：全局、局部、纹理、常量、共享和寄存器内存。每一种类型的记忆都有其优点和缺点。片上存储器只有寄存器和共享存储器两种类型。本地存储器、全局存储器、常量存储器和纹理存储器都驻留在片外。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915224834617.png" alt="image-20230915224834617" style="zoom:67%;" />

​		作为一个附注，GPU 和 FPGA 等边缘设备具有不同的计算能力和内存资源。所提出的访存优化技术，包括零拷贝访存、数据查找表、数据分割和流水线等，普遍适用于各种 GPU 和 FPGA ，有助于减少所需的访存次数，最终减少边缘处的能量开销。

##### 零拷贝内存


​	主机与 GPU 设备之间的数据传输往往会导致计算资源的闲置，成为性能瓶颈。异步传输版本允许数据传输与计算重叠，可用于隐藏主机与设备之间的数据传输。零拷贝内存是一种异步内存映射方法，它将 pinned (不可分页的)主机内存直接映射到 GPU 内存，并隐式地将其传输到 GPU 中。它允许 GPU 线程直接访问主机内存。当 GPU 线程读取主机映射的变量时，它提交一个 PCIe 读事务，主机将通过 PCIe 总线返回数据。与其他 cudaMemcpy 方法相比，零拷贝内存允许 CPU - GPU 内存传输与计算重叠。

​	图8所示为零知识证明中应用的零拷贝存储过程。当 GPU 线程读取数据时，它会提前发送一个信号，并继续进行计算；并且将数据从 CPU 内存映射到后台的零拷贝内存中。最终，GPU 线程直接从零拷贝内存中读取数据，而不是从GPU 缓存中读取数据。在适当的工作负载下，GPU 可以与 PCIe 传输重叠计算，可以获得更高的性能，同时也不需要分配 GPU 内存缓冲区。 

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915232059440.png" alt="image-20230915232059440" style="zoom:50%;" />

​		然而，还有几件事情需要考虑。首先，由于映射后的缓冲区由 CPU 和 GPU共享，开发人员必须使用现有的上下文、流或事件 API 来同步访问。当应用程序想要读取 GPU 写入到一个映射的固定缓冲区的数据时，通常需要同步。如果应用程序正在使用多重缓冲来最大化 CPU / GPU 的并发执行，那么在开始写入可能仍在被 GPU 读取的缓冲区之前，可能必须进行同步。其次，由于数据未在GPU上缓存，映射后的固定内存只需读写一次，并将读写该内存的全局负载和存储进行合并。由于任何对此类内存区域的重复访问都会导致 CPU - GPU 的重复传输，并且在我们的模型中数据的内存访问次数存在差异，为了有效地提高传输速率和有效地利用 GPU 的内存结构，需要对只访问一次的数据使用零拷贝内存。对于需要重复访问的数据，需要采用其他的解决方案。

##### 查找表

​	在零知识证明中，有些数据是重复访问的，无法通过零拷贝内存方法进行传输。提出了一个查找表来存储重复访问的数据。查找表是同类型数据的集合，可以支持对表中数据进行查找、读取、插入和删除等操作。查找表有静态和动态两种类型。静态查找表只支持搜索和读取，动态查找表支持全部4种操作。在实际应用中，零知识证明中存在大量的缓存缺失，因此只读静态查找表性能较差。

​	因此，在零知识证明中采用了动态查找表，如图 9 中的算法流程图所示。具体来说，在 GPU 的共享内存中建立一个查找表，因为共享内存在进行写操作时是庞大且快速的。**在初始化时，将前期可能频繁访问的数据放在以数组形式实现的查找表中**。GPU 执行计算时，首先从查找表中查询数据。如果查询为未命中，将从主机获取数据，如果需要，将更新查找表。一开始，更新和替换会更加频繁。当数据稳定时，更新次数会减少。**此时，一棵二叉树将代替初始数组进行快速查询和更新**。**图10 所示为我们描述的基于组合查找表和零拷贝访存方法的数据获取过程。通过结合的方法，主机和设备之间的数据交换成本显著降低。**

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915233514657.png" alt="image-20230915233514657" style="zoom:67%;" />

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915233704120.png" alt="image-20230915233704120" style="zoom:67%;" />



##### 数据分层

​	当输入的位宽大于GPU缓存的位宽时，会造成短时阻塞，增加传输延迟。不同的 GPU 设备具有不同的位宽。例如，Nvidia 2080 Ti 的位宽为 352 bit，V100 的位宽为 4096 bit。**采用数据分割方法对高位宽数据进行处理，以 GPU 位宽作为阈值判断数据块是否为大尺寸进行切片**。图11 给出了数据分割的过程。更具体地说，在数据分割模式中，数据在进入流水线之前被分割成多个块；并在 GPU 中进行处理后，再次对这些线段进行拼接。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915233836093.png" alt="image-20230915233836093" style="zoom:67%;" />

##### 一种集成的数据获取方法

​	除了普通的主机-设备传输方法外，结合三种优化的数据获取模式，零知识证明算法具有图 11 所述的集成数据获取方法。

- 模式1：小规模且只访问一次的数据存储在零拷贝内存中。如果需要，GPU线程将直接访问这些数据。
- 模式2：重复访问的数据存储在共享内存中经过预处理的查找表中。GPU线程将首先搜索查找表。如果存在缓存缺失，GPU 线程读取内存，并在必要时更新查找表。
- 模式3：对于大尺寸数据，在数据被带入 GPU 内存之前进行分区。



#### 实现

​	在这一部分中，我们描述了整体框架的实现细节。表1给出了实验中所用到的CPU 和 GPU 的规格说明。系统版本为 Ubuntu 18.04，工具链版本为 CUDA 10.1。

![image-20230915234137270](C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915234137270.png)



​		算法1是内积论证过程中的一种具体的协同加速方案。参数的交流量减少了1/ 3。证明者和验证者根据公式 ( 1 ) - ( 4 )计算。当涉及并行内积计算和椭圆曲线计算时，将数据送入GPU进行并行计算，并将结果暂时存储，直至使用。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915234259602.png" alt="image-20230915234259602" style="zoom:67%;" />

##### 数据分类

​	如前文第4节所述，在处理前将数据分为3类：

- z _ data：规模较小且只访问一次的数据，称为z _ data。这些数据通过模式1获取。
- l _ data：重复访问的数据称为l _ data。
- s _ data：位宽大于352 bit2的数据称为s _ data。这些数据通过模式3获取。


​		数据分类由 Perf 工具辅助。Perf是Linux内核中的系统性能优化工具，可以对 CPU 性能计数器、tracepoints、kprobes 和 uprobes (动态跟踪) 进行插桩。因此，可以用它来查看和分析程序运行。例如，perf stat用于查看进程切换次数、缓存利用率，perf tracepoint用于采样tick时间点以获取内核代码中的热点。



##### 零拷贝内存

​		零拷贝内存借助 CUDA 库函数实现。如图12所示，我们描述了调用 API及其函数的过程。

- 首先，使用 cudaGetDeviceProperties ( )判断 GPU 版本是否支持主机内存到 GPU 的直接映射。
- 其次，cudaDeviceMapHost ( ) 调用 cudaSetDeviceFlags ( ) 启动固定内存映射。这是因为固定内存由主机和设备共享，因此需要保持同步，防止同时修改零拷贝内存中的数据被一方以上修改。
- 第三，调用cudaMallocHost ( )分配 pinned 内存映射主机内存，并通过调用cudaHostGetDevicePointer ( )获得映射设备地址空间的指针。
- 最后，使用cudaFreeHost ( ) 释放被 pinned 的内存。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915234558997.png" alt="image-20230915234558997" style="zoom:67%;" />

##### 查找表

​	 在实现查找表时，表大小的确定至关重要。在实际应用中，我们逐渐增加表大小，并观察模型计算中的性能指标，包括命中率、初始化所需时间和时间成本。实验中使用的共享内存为 48 KB。

​		图 13 表明，随着查找表大小的增加，命中率也随之增加，并逐渐趋近于一个恒定值。这是因为规模越大，可以提前存储的数据就越多。同样，查找表规模越大，初始化查找表所需时间越长，但后续模型计算所需时间越短。然而，当查找表的大小大于一个阈值时，初始化时间和随后的模型计算时间都会迅速增加。这是因为当查找表过大时，没有足够的空间来维护共享内存自身的功能。综合考虑各项性能指标，实验中置查找表大小为 24 KB。


​		由于 Fibonacci 搜索算法具有整体性能好、搜索速度快等优点，我们采用该算法对查找表进行搜索和更新。图14 表明，随着查找表的不断更新，命中率也在增加。表大小设置为24 KB。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915232436060.png" alt="image-20230915232436060" style="zoom:67%;" />

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915233228042.png" alt="image-20230915233228042" style="zoom:67%;" />

##### 数据分层

​		算法 2 描述了位宽大于 352 bit 数据的数据分割过程。数据被分割成多个大小为 320 比特的切片。切片的大小应该是一个16 的倍数。在实验中，在Nvidia 2080Ti上，320 位的切片表现最好。对每个切片进行 Prover 操作，并将结果进行组装，将最终的证明器 𝑃 重新放置。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915234923525.png" alt="image-20230915234923525" style="zoom:67%;" />

##### 实施平行交易

​		在图 15 中，我们描述了并行事务的流程图。交易有两种，透明和保密。与透明交易相比，保密交易需要零知识证明来验证合法性，而透明交易则不需要零知识证明。机密事务除了需要一对验证身份的密钥外，还需要多一对验证数据地址的密钥。同时，透明交易只需要一对密钥来验证身份。最后，支持保密交易的数据结构比支持透明交易的数据结构更复杂。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915235026060.png" alt="image-20230915235026060" style="zoom:67%;" />



#### 性能评价

##### 加速单个 Bulletproof

​		The experiments are conducted on a Docker image of version 20.10.3 on Intel® Xeon® Gold 6230 CPU @2.10 GHz, with the GPU devices of NVIDIA® Cuda release 10.1 on NVIDIA® GeForce® RTX 2080 Ti/NVIDIA® or Tesla® V100 to evaluate the performance. The Pedersen data and various hash functions are used as the input data.

​		图 16 报告了Bulletproof 范围验证程序在 RTX 2080Ti 平台上的证明和验证运行时间。我们将输入大小从( 1-bit , 1-commit) 逐渐增加到 ( 512位, 256位)。从图16可以看出，随着输入位宽的增加，算法1的加速比在证明和验证过程中都有所增加。验证过程的加速比略大于证明过程的加速比。这是因为验证中包含了更多的可并行化的椭圆曲线点算术运算。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915235256853.png" alt="image-20230915235256853" style="zoom:67%;" />

​		为了论证算法 1 的普遍适用性，探究不同 GPU 平台的加速能力，实验还在V100 平台上进行了测试。输入数据为 Pedersen Hash varying from 8-bit (Pedersen-3) to 8192-bit (Pedersen3072).

​		表 2 给出了 Bulletproofs 电路模块中的校验过程在不同 GPU 平台上有加速和无加速时的运行时间。可以看出，不同 GPU 设备之间的加速比没有显著差异。与 RTX 2080 相比，功能更强大的 Tesla V100 并不一定能获得更高的加速比。我们得出结论，算法1有能力在具有足够内核的广泛GPU设备上表现良好。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915235513299.png" alt="image-20230915235513299" style="zoom:67%;" />				

​		此外，图 17 给出了 Bulletproofs 电路模块中的证明过程在不同GPU平台上的加速比。可以看出，在 2080Ti 上，随着验证比特数的增加，证明过程的加速比可能会略大，而在V100上的加速比更加稳定。2080Ti 的加速比除了开始时的小幅跳变外，主要体现在输入数据位宽在 256 ~ 512 之间时的小幅下降。这也与我们 2080Ti 的位宽为 352bit 的判断一致。V100 的情况并非如此，因为其4096位的位宽足够大。因此，我们提出将数据划分为多个与GPU位宽对齐的切片。

<img src="C:\Users\lijiayong\AppData\Roaming\Typora\typora-user-images\image-20230915235630699.png" alt="image-20230915235630699" style="zoom:67%;" />

##### 加速多次交易

7.2 部分...
